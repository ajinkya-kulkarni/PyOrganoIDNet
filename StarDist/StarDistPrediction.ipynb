{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584573cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# Configuration to avoid generating __pycache__ and limit traceback for cleaner exceptions\n",
    "sys.dont_write_bytecode = True\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "def download_and_setup_model(option):\n",
    "    python_file_url = 'https://raw.githubusercontent.com/ajinkya-kulkarni/PyBlendPatches/main/modules.py'\n",
    "    python_filename = 'modules.py'\n",
    "    zip_file_url = ''\n",
    "    zip_filename = ''\n",
    "    model_folder_path = ''\n",
    "\n",
    "    if option == 'stardist':\n",
    "        zip_file_url = 'https://github.com/ajinkya-kulkarni/TrainedModels/raw/main/StarDist/stardist_model.zip'\n",
    "        zip_filename = 'StarDistTrainedModel.zip'\n",
    "        model_folder_path = 'stardist_model'\n",
    "    elif option == 'cellpose':\n",
    "        zip_file_url = 'https://github.com/ajinkya-kulkarni/TrainedModels/raw/main/Cellpose/cellpose_model.zip'\n",
    "        zip_filename = 'CellposeTrainedModel.zip'\n",
    "        model_folder_path = 'cellpose_model.693768'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid option: {option}\")\n",
    "\n",
    "    # Download and save the Python file from the URL\n",
    "    if os.path.exists(python_filename):\n",
    "        os.remove(python_filename)\n",
    "    with requests.get(python_file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, \n",
    "                            desc = f'Downloading {python_filename}')\n",
    "        with open(python_filename, 'wb') as f:\n",
    "            for data in r.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "        progress_bar.close()\n",
    "\n",
    "    # Download and extract the zip file\n",
    "    if os.path.exists(zip_filename):\n",
    "        os.remove(zip_filename)\n",
    "    if os.path.isdir(model_folder_path):\n",
    "        shutil.rmtree(model_folder_path)\n",
    "    if os.path.isfile(model_folder_path):\n",
    "        os.remove(model_folder_path)\n",
    "    with requests.get(zip_file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, \n",
    "                            desc = f'Downloading {option} model')\n",
    "        with open(zip_filename, 'wb') as f:\n",
    "            for data in r.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "        progress_bar.close()\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    os.remove(zip_filename)\n",
    "    \n",
    "    return model_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8ca570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30da07fec7eb4bdd890a91111807ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.py:   0%|          | 0.00/4.32k [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc2a501062d4d378510384f0552aee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading stardist model:   0%|          | 0.00/10.6M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = download_and_setup_model('stardist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71403700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6db5fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "532ce412",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/ajinkya/Desktop/PyOrganoidAnalysis/DataSetPreparation/Test_Set'\n",
    "data_dir = os.path.join(folder_path, 'images', '*.tif')\n",
    "\n",
    "predict_images_path = sorted([f for f in glob.glob(data_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf6d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.64351, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from contextlib import redirect_stdout\n",
    "from stardist.models import StarDist2D\n",
    "\n",
    "model = StarDist2D(None, name=model_path, basedir='.')\n",
    "\n",
    "def predict_mask_from_image_stardist(img_patch):\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts a segmentation mask from an image patch.\n",
    "\n",
    "    This function takes an image patch and uses a pre-defined model\n",
    "    to predict the segmentation mask. It silences any print output during the prediction \n",
    "    to keep the console clean. The function assumes that the model is already \n",
    "    loaded and available in the global scope.\n",
    "\n",
    "    Args:\n",
    "    img_patch (numpy array): The image patch for which to predict the segmentation mask.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The predicted segmentation mask, where each pixel's intensity corresponds to a label.\n",
    "    \"\"\"\n",
    "\n",
    "    with redirect_stdout(open(os.devnull, \"w\")) as f:\n",
    "\n",
    "        # Performing the prediction using the pre-defined model\n",
    "        mask, details = model.predict_instances(img_patch)\n",
    "\n",
    "    # Returning the predicted segmentation mask\n",
    "    \n",
    "    # Check if the mask is empty (all zeros)\n",
    "    if np.any(mask):\n",
    "        # Return the predicted mask if it's not empty\n",
    "        return mask.astype('uint16')\n",
    "    else:\n",
    "        # Return an array of zeros if the mask is empty\n",
    "        return np.zeros(img_patch.shape, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0013855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 800\n",
    "overlap = int(0.5 * window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f23406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba09ce5cd7647e98c77dc6f19d36ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading images and predicting:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_array = []\n",
    "labels_array = []\n",
    "\n",
    "for image_path in tqdm(predict_images_path, desc='Reading images and predicting', leave = True):\n",
    "    \n",
    "    normalized_img = read_image_as_grayscale_then_MinMax_normalize(image_path)\n",
    "        \n",
    "    ###########################################################################################\n",
    "\n",
    "    patches, window_coords = patchify(normalized_img, window_size, overlap)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    predicted_labels = []\n",
    "\n",
    "    for patch in tqdm(patches, desc = 'Predicting on patches', leave = False):\n",
    "    \n",
    "        label = predict_mask_from_image_stardist(patch)\n",
    "    \n",
    "        smoothed_label = smooth_segmented_labels(label)\n",
    "    \n",
    "        predicted_labels.append(smoothed_label)\n",
    "\n",
    "    ###########################################################################################\n",
    "    \n",
    "    border_cleaned_predicted_labels = []\n",
    "    \n",
    "    for patch, patch_coords in zip(predicted_labels, window_coords):\n",
    "        cleaned_patch = remove_border_labels(patch, patch_coords, normalized_img)\n",
    "        border_cleaned_predicted_labels.append(cleaned_patch)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    \n",
    "    region_info_list = compile_label_info(np.array(border_cleaned_predicted_labels), window_coords)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    # First, extract the bounding boxes from each region in the region_info_list\n",
    "    # This creates an array of bounding boxes where each box is defined by [x_min, y_min, x_max, y_max]\n",
    "    boxes = np.array([region['global_bbox'] for region in region_info_list])\n",
    "    \n",
    "    # Apply the Non-Maximum Suppression (NMS) function to these boxes.\n",
    "    # NMS will analyze these bounding boxes and return the indices of boxes that should be kept\n",
    "    # based on the overlap threshold of 0.5. Boxes that overlap more than this threshold with a larger box\n",
    "    # will be filtered out.\n",
    "    nms_indices = non_maximum_suppression(boxes, overlapThresh=0.5)\n",
    "    \n",
    "    # Using the indices obtained from NMS, construct the final list of regions.\n",
    "    # This list will only include regions whose bounding boxes were selected by the NMS process,\n",
    "    # effectively filtering out regions with significantly overlapping bounding boxes.\n",
    "    nms_region_info_list = [region_info_list[i] for i in nms_indices]\n",
    "    \n",
    "    # final_region_info_list now contains the refined list of regions after applying NMS.\n",
    "    # These are the regions that are considered significant based on their size and the lack of substantial\n",
    "    # overlap with larger regions.\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    canvas = place_labels_on_canvas(normalized_img, nms_region_info_list)\n",
    "    \n",
    "    mask_filename = os.path.join(folder_path, 'AlgorithmPredictions', \n",
    "                                 os.path.splitext(os.path.basename(image_path))[0] + '_StarDistMask.tif')\n",
    "\n",
    "    if os.path.exists(mask_filename):\n",
    "        os.remove(mask_filename)\n",
    "    canvas_image = Image.fromarray(canvas)\n",
    "    canvas_image.save(mask_filename, format='TIFF')\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    images_array.append(np.asarray(normalized_img))\n",
    "    labels_array.append(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e070b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
