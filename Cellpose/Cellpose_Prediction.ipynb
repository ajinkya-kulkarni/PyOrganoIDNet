{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8ab2e1-2467-4a4b-bf30-156820feb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77acbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# URL and filename for the Python file\n",
    "python_file_url = 'https://raw.githubusercontent.com/ajinkya-kulkarni/PyBlendPatches/main/modules.py'\n",
    "python_filename = 'modules.py'\n",
    "\n",
    "# Remove the existing file if it exists\n",
    "if os.path.exists(python_filename):\n",
    "    os.remove(python_filename)\n",
    "\n",
    "# Download and save the Python file\n",
    "response = requests.get(python_file_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "with open(python_filename, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36085b49-8fc7-4467-ab5a-5b3247a11ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Pretrained_Model', 'Cellpose_Pretrained_Model.379168')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60835e3f-1f68-48d3-9aa2-23faf14c6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('AlgorithmPredictions'):\n",
    "    shutil.rmtree('AlgorithmPredictions')\n",
    "os.mkdir('AlgorithmPredictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dadf4fd-a8e7-4ae1-9ae5-c5ef85e65fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Configuration to avoid generating __pycache__ and limit traceback for cleaner exceptions\n",
    "sys.dont_write_bytecode = True\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0867e634-c91b-49cb-910e-e6c7a57326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58ce8099-2aca-448f-ba97-a7733dfa9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "\n",
    "def predict_mask_from_image_cellpose(normalized_img_patch, gpu_usage = False):\n",
    "\n",
    "    model = models.CellposeModel(gpu = gpu_usage, pretrained_model = model_path)\n",
    "    \n",
    "    channels = [[0, 0]]\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts a segmentation mask from an image patch using a given model.\n",
    "    Args:\n",
    "    normalized_img_patch (numpy array): The normalized image patch for prediction.\n",
    "    model (object): The segmentation model used for predicting the mask.\n",
    "    channels (list): A list of channels to be used in the prediction.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The predicted segmentation mask.\n",
    "    \"\"\"\n",
    "\n",
    "    mask, flow, style = model.eval(normalized_img_patch, diameter=None, channels=channels)\n",
    "\n",
    "    # Check if the mask is empty (all zeros)\n",
    "    if np.any(mask):\n",
    "        # Return the predicted mask if it's not empty\n",
    "        return mask.astype('uint16')\n",
    "    else:\n",
    "        # Return an array of zeros if the mask is empty\n",
    "        return np.zeros(normalized_img_patch.shape, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7c633e-7731-4546-a3ba-eb492076e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join('/home', 'ajinkya', 'Desktop', 'PyOrganoidAnalysis', 'Dataset', 'Test')\n",
    "data_dir = os.path.join(folder_path, 'Images', '*.tif')\n",
    "\n",
    "predict_images_path = sorted([f for f in glob.glob(data_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5894c3b9-5a41-4c17-bbe3-e2ab023e61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 800\n",
    "overlap = int(0.5 * window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13b1214f-b2cb-4d2c-9167-3f85c486bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b7d4f39c484b4cab7f3ca709a56d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading images and predicting:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_array = []\n",
    "labels_array = []\n",
    "\n",
    "for image_path in tqdm(predict_images_path, desc='Reading images and predicting', leave = True):\n",
    "    \n",
    "    normalized_img = read_image_as_grayscale_then_MinMax_normalize(image_path)\n",
    "        \n",
    "    ###########################################################################################\n",
    "\n",
    "    patches, window_coords = patchify(normalized_img, window_size, overlap)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    predicted_labels = []\n",
    "\n",
    "    for patch in tqdm(patches, desc = 'Predicting on patches', leave = False):\n",
    "    \n",
    "        label = predict_mask_from_image_cellpose(patch, gpu_usage = True)\n",
    "    \n",
    "        smoothed_label = smooth_segmented_labels(label)\n",
    "    \n",
    "        predicted_labels.append(smoothed_label)\n",
    "\n",
    "    ###########################################################################################\n",
    "    \n",
    "    border_cleaned_predicted_labels = []\n",
    "    \n",
    "    for patch, patch_coords in zip(predicted_labels, window_coords):\n",
    "        cleaned_patch = remove_border_labels(patch, patch_coords, normalized_img)\n",
    "        border_cleaned_predicted_labels.append(cleaned_patch)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    \n",
    "    region_info_list = compile_label_info(np.array(border_cleaned_predicted_labels), window_coords)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    # First, extract the bounding boxes from each region in the region_info_list\n",
    "    # This creates an array of bounding boxes where each box is defined by [x_min, y_min, x_max, y_max]\n",
    "    boxes = np.array([region['global_bbox'] for region in region_info_list])\n",
    "    \n",
    "    # Apply the Non-Maximum Suppression (NMS) function to these boxes.\n",
    "    # NMS will analyze these bounding boxes and return the indices of boxes that should be kept\n",
    "    # based on the overlap threshold of 0.5. Boxes that overlap more than this threshold with a larger box\n",
    "    # will be filtered out.\n",
    "    nms_indices = non_maximum_suppression(boxes, overlapThresh=0.5)\n",
    "    \n",
    "    # Using the indices obtained from NMS, construct the final list of regions.\n",
    "    # This list will only include regions whose bounding boxes were selected by the NMS process,\n",
    "    # effectively filtering out regions with significantly overlapping bounding boxes.\n",
    "    nms_region_info_list = [region_info_list[i] for i in nms_indices]\n",
    "    \n",
    "    # final_region_info_list now contains the refined list of regions after applying NMS.\n",
    "    # These are the regions that are considered significant based on their size and the lack of substantial\n",
    "    # overlap with larger regions.\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    canvas = place_labels_on_canvas(normalized_img, nms_region_info_list)\n",
    "    \n",
    "    mask_filename = os.path.join('AlgorithmPredictions', \n",
    "                                 os.path.splitext(os.path.basename(image_path))[0] + '_CellposeMask.tif')\n",
    "    \n",
    "    if os.path.exists(mask_filename):\n",
    "        os.remove(mask_filename)\n",
    "    canvas_image = Image.fromarray(canvas)\n",
    "    canvas_image.save(mask_filename, format='TIFF')\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    images_array.append(np.asarray(normalized_img))\n",
    "    labels_array.append(canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cd1b66a-60b5-4ac4-99c1-f4c3a64880bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_file = 'modules.py'\n",
    "if os.path.exists(modules_file):\n",
    "    os.remove(modules_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e41704-672a-4899-90a6-a56eb5e34973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
