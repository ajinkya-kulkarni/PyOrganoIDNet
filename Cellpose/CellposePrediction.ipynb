{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8ab2e1-2467-4a4b-bf30-156820feb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77acbff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# Configuration to avoid generating __pycache__ and limit traceback for cleaner exceptions\n",
    "sys.dont_write_bytecode = True\n",
    "sys.tracebacklimit = 0\n",
    "\n",
    "def download_and_setup_model(option):\n",
    "    python_file_url = 'https://raw.githubusercontent.com/ajinkya-kulkarni/PyBlendPatches/main/modules.py'\n",
    "    python_filename = 'modules.py'\n",
    "    zip_file_url = ''\n",
    "    zip_filename = ''\n",
    "    model_folder_path = ''\n",
    "\n",
    "    if option == 'stardist':\n",
    "        zip_file_url = 'https://github.com/ajinkya-kulkarni/TrainedModels/raw/main/StarDist/stardist_model.zip'\n",
    "        zip_filename = 'StarDistTrainedModel.zip'\n",
    "        model_folder_path = 'stardist_model'\n",
    "    elif option == 'cellpose':\n",
    "        zip_file_url = 'https://github.com/ajinkya-kulkarni/TrainedModels/raw/main/Cellpose/cellpose_model.zip'\n",
    "        zip_filename = 'CellposeTrainedModel.zip'\n",
    "        model_folder_path = 'cellpose_model.832291'\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid option: {option}\")\n",
    "\n",
    "    # Download and save the Python file from the URL\n",
    "    if os.path.exists(python_filename):\n",
    "        os.remove(python_filename)\n",
    "    with requests.get(python_file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, \n",
    "                            desc = f'Downloading {python_filename}')\n",
    "        with open(python_filename, 'wb') as f:\n",
    "            for data in r.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "        progress_bar.close()\n",
    "\n",
    "    # Download and extract the zip file\n",
    "    if os.path.exists(zip_filename):\n",
    "        os.remove(zip_filename)\n",
    "    if os.path.isdir(model_folder_path):\n",
    "        shutil.rmtree(model_folder_path)\n",
    "    if os.path.isfile(model_folder_path):\n",
    "        os.remove(model_folder_path)\n",
    "    with requests.get(zip_file_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size_in_bytes = int(r.headers.get('content-length', 0))\n",
    "        block_size = 1024\n",
    "        progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, \n",
    "                            desc = f'Downloading {option} model')\n",
    "        with open(zip_filename, 'wb') as f:\n",
    "            for data in r.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                f.write(data)\n",
    "        progress_bar.close()\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "    os.remove(zip_filename)\n",
    "    \n",
    "    return model_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36085b49-8fc7-4467-ab5a-5b3247a11ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff69beb5fa47d9ad227cd21f242f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.py:   0%|          | 0.00/4.32k [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6029012c65432d951f1380a26bbcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading cellpose model:   0%|          | 0.00/24.7M [00:00<?, ?iB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = download_and_setup_model('cellpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dadf4fd-a8e7-4ae1-9ae5-c5ef85e65fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0867e634-c91b-49cb-910e-e6c7a57326db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ce8099-2aca-448f-ba97-a7733dfa9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "\n",
    "def predict_mask_from_image_cellpose(normalized_img_patch, gpu_usage = False):\n",
    "\n",
    "    model = models.CellposeModel(gpu = gpu_usage, pretrained_model = model_path)\n",
    "    \n",
    "    channels = [[0, 0]]\n",
    "\n",
    "    \"\"\"\n",
    "    Predicts a segmentation mask from an image patch using a given model.\n",
    "    Args:\n",
    "    normalized_img_patch (numpy array): The normalized image patch for prediction.\n",
    "    model (object): The segmentation model used for predicting the mask.\n",
    "    channels (list): A list of channels to be used in the prediction.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The predicted segmentation mask.\n",
    "    \"\"\"\n",
    "\n",
    "    mask, flow, style = model.eval(normalized_img_patch, diameter=None, channels=channels)\n",
    "\n",
    "    # Check if the mask is empty (all zeros)\n",
    "    if np.any(mask):\n",
    "        # Return the predicted mask if it's not empty\n",
    "        return mask.astype('uint16')\n",
    "    else:\n",
    "        # Return an array of zeros if the mask is empty\n",
    "        return np.zeros(normalized_img_patch.shape, dtype=np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7c633e-7731-4546-a3ba-eb492076e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/home/ajinkya/Desktop/PyOrganoidAnalysis/Prediction_Images'\n",
    "data_dir = os.path.join(folder_path, '*.tif')\n",
    "\n",
    "predict_images_path = sorted([f for f in glob.glob(data_dir) \n",
    "                       if not any(prefix in f for prefix in ['StarDist_', 'Cellpose_'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5894c3b9-5a41-4c17-bbe3-e2ab023e61cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 800\n",
    "overlap = int(0.5 * window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13b1214f-b2cb-4d2c-9167-3f85c486bb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db38bdcd47c44139d48f12994445918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading images and predicting:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting on patches:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_array = []\n",
    "labels_array = []\n",
    "nms_region_info_list_array = []\n",
    "\n",
    "for image_path in tqdm(predict_images_path, desc='Reading images and predicting', leave = True):\n",
    "    \n",
    "    normalized_img = read_image_as_grayscale_then_MinMax_normalize(image_path)\n",
    "        \n",
    "    ###########################################################################################\n",
    "\n",
    "    patches, window_coords = patchify(normalized_img, window_size, overlap)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    predicted_labels = []\n",
    "\n",
    "    for patch in tqdm(patches, desc = 'Predicting on patches', leave = False):\n",
    "    \n",
    "        label = predict_mask_from_image_cellpose(patch, gpu_usage = True)\n",
    "    \n",
    "        smoothed_label = smooth_segmented_labels(label)\n",
    "    \n",
    "        predicted_labels.append(smoothed_label)\n",
    "\n",
    "    ###########################################################################################\n",
    "    \n",
    "    border_cleaned_predicted_labels = []\n",
    "    \n",
    "    for patch, patch_coords in zip(predicted_labels, window_coords):\n",
    "        cleaned_patch = remove_border_labels(patch, patch_coords, normalized_img)\n",
    "        border_cleaned_predicted_labels.append(cleaned_patch)\n",
    "        \n",
    "    ###########################################################################################\n",
    "    \n",
    "    region_info_list = compile_label_info(np.array(border_cleaned_predicted_labels), window_coords)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    # First, extract the bounding boxes from each region in the region_info_list\n",
    "    # This creates an array of bounding boxes where each box is defined by [x_min, y_min, x_max, y_max]\n",
    "    boxes = np.array([region['global_bbox'] for region in region_info_list])\n",
    "    \n",
    "    # Apply the Non-Maximum Suppression (NMS) function to these boxes.\n",
    "    # NMS will analyze these bounding boxes and return the indices of boxes that should be kept\n",
    "    # based on the overlap threshold of 0.5. Boxes that overlap more than this threshold with a larger box\n",
    "    # will be filtered out.\n",
    "    nms_indices = non_maximum_suppression(boxes, overlapThresh=0.5)\n",
    "    \n",
    "    # Using the indices obtained from NMS, construct the final list of regions.\n",
    "    # This list will only include regions whose bounding boxes were selected by the NMS process,\n",
    "    # effectively filtering out regions with significantly overlapping bounding boxes.\n",
    "    nms_region_info_list = [region_info_list[i] for i in nms_indices]\n",
    "    \n",
    "    # final_region_info_list now contains the refined list of regions after applying NMS.\n",
    "    # These are the regions that are considered significant based on their size and the lack of substantial\n",
    "    # overlap with larger regions.\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    canvas = place_labels_on_canvas(normalized_img, nms_region_info_list)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    images_array.append(np.asarray(normalized_img))\n",
    "    labels_array.append(canvas)\n",
    "    nms_region_info_list_array.append(nms_region_info_list)\n",
    "    \n",
    "    ###########################################################################################\n",
    "    \n",
    "    # Create a figure with 4 subplots\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    # First subplot: Display the original image\n",
    "    axes[0].imshow(normalized_img, cmap='gray', alpha=1)\n",
    "    axes[0].set_title('Image')\n",
    "    axes[0].set_xticks([])\n",
    "    axes[0].set_yticks([])\n",
    "    \n",
    "    # Second subplot: Display the mask\n",
    "    axes[1].imshow(canvas, cmap=lbl_cmap, alpha=1)\n",
    "    axes[1].set_title('Mask')\n",
    "    axes[1].set_xticks([])\n",
    "    axes[1].set_yticks([])\n",
    "    \n",
    "    # Third subplot (now switched): Display the image with bounding boxes\n",
    "    for region in nms_region_info_list:\n",
    "        x_min, y_min, x_max, y_max = region['global_bbox']\n",
    "        rect = mpatches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, \n",
    "                                 linewidth=0.5, edgecolor='tab:orange', facecolor='none')\n",
    "        axes[2].add_patch(rect)\n",
    "    axes[2].imshow(normalized_img, cmap='gray', alpha=1)\n",
    "    axes[2].set_title('Bounding Boxes')\n",
    "    axes[2].set_xticks([])\n",
    "    axes[2].set_yticks([])\n",
    "    \n",
    "    # Fourth subplot (now switched): Display the overlay of image and mask\n",
    "    mask_float = np.float32(canvas)\n",
    "    mask_float[mask_float == 0] = np.nan\n",
    "    axes[3].imshow(normalized_img, cmap='gray', alpha=1)\n",
    "    axes[3].imshow(mask_float, cmap=lbl_cmap, alpha=0.5)\n",
    "    axes[3].set_title('Overlay')\n",
    "    axes[3].set_xticks([])\n",
    "    axes[3].set_yticks([])\n",
    "    \n",
    "    # Save the figure\n",
    "    filename = os.path.join(folder_path, 'Cellpose_' + os.path.basename(image_path))\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    plt.savefig(filename, dpi=300, format='tif', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d957c3ab-60fc-435b-8778-52c271baed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in a dictionary\n",
    "data_dict = {'images': images_array, 'masks': labels_array, 'nms_region_info_list': nms_region_info_list_array}\n",
    "\n",
    "filename = 'CellPose_predictions.pkl'\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "\n",
    "# Save the dictionary to a pickle file\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010d689-487d-495e-b3a3-d549dca6be4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
